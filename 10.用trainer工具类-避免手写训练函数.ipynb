{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db0cb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennywu/opt/anaconda3/envs/dl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.0/29.0 [00:00<00:00, 2.91kB/s]\n",
      "Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [00:00<00:00, 145kB/s]\n",
      "Downloading (â€¦)solve/main/vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213k/213k [00:00<00:00, 466kB/s]\n",
      "Downloading (â€¦)/main/tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436k/436k [00:00<00:00, 650kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "#åŠ è½½åˆ†è¯å·¥å…·\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c941b73",
   "metadata": {},
   "source": [
    "AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b6b4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/kennywu/Documents/Github_repos/Huggingface_CN_Toturials/data/glue_sst2/train/cache-d5a332e72039e5e9_*_of_00004.arrow\n",
      "Loading cached processed dataset at /Users/kennywu/Documents/Github_repos/Huggingface_CN_Toturials/data/glue_sst2/validation/cache-54ebd1d2495e5e86_*_of_00004.arrow\n",
      "Loading cached processed dataset at /Users/kennywu/Documents/Github_repos/Huggingface_CN_Toturials/data/glue_sst2/test/cache-47c71c904c75dba8_*_of_00004.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "#åŠ è½½æ•°æ®é›†\n",
    "#ä»Žç½‘ç»œåŠ è½½\n",
    "#datasets = load_dataset(path='glue', name='sst2')\n",
    "\n",
    "#ä»Žæœ¬åœ°ç£ç›˜åŠ è½½æ•°æ®\n",
    "datasets = load_from_disk('./data/glue_sst2')\n",
    "\n",
    "\n",
    "#åˆ†è¯\n",
    "def f(data):\n",
    "    return tokenizer(\n",
    "        data['sentence'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=30,\n",
    "    )\n",
    "\n",
    "\n",
    "datasets = datasets.map(f, batched=True, batch_size=1000, num_proc=4)\n",
    "\n",
    "#å–æ•°æ®å­é›†ï¼Œå¦åˆ™æ•°æ®å¤ªå¤šè·‘ä¸åŠ¨\n",
    "dataset_train = datasets['train'].shuffle().select(range(1000))\n",
    "dataset_test = datasets['validation'].shuffle().select(range(200))\n",
    "\n",
    "del datasets\n",
    "\n",
    "dataset_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6ce4d24",
   "metadata": {},
   "source": [
    "ç”¨AutoModelForSequenceClassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74b91f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10831.181\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "#åŠ è½½æ¨¡åž‹ AutoModelForSequenceClassificationï¼ŒæŒ‡å®šä¸º2åˆ†ç±»\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased',\n",
    "                                                           num_labels=2)\n",
    "\n",
    "print(sum([i.nelement() for i in model.parameters()]) / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876c0287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w9/g6sxmrzn3bj5clmc2jx9vzt40000gn/T/ipykernel_53185/623941755.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('accuracy')\n",
      "Downloading builder script: 4.21kB [00:00, 1.06MB/s]                   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "#åŠ è½½è¯„ä»·å‡½æ•°\n",
    "#æœ‰æ—¶ä¼šå› ä¸ºç½‘ç»œé—®é¢˜å¡ä¸»,åå¤å°è¯•ä¼šæˆåŠŸçš„\n",
    "metric = load_metric('accuracy')\n",
    "\n",
    "\n",
    "#å®šä¹‰è¯„ä»·å‡½æ•°\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = logits.argmax(axis=1)\n",
    "    return metric.compute(predictions=logits, references=labels)\n",
    "\n",
    "\n",
    "#æ¨¡æ‹Ÿæµ‹è¯•è¾“å‡º\n",
    "eval_pred = EvalPrediction(\n",
    "    predictions=np.array([[0, 1], [2, 3], [4, 5], [6, 7]]),\n",
    "    label_ids=np.array([1, 1, 1, 1]),\n",
    ")\n",
    "\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7e6b295",
   "metadata": {},
   "source": [
    "# transformersçš„ TrainingArguments, Trainer\n",
    "transformersåº“ä¸­ç”¨äºŽè®­ç»ƒæ¨¡åž‹çš„ä¸¤ä¸ªé‡è¦ç±»ã€‚\n",
    "\n",
    "## TrainingArgumentsæ˜¯ä¸€ä¸ªç”¨äºŽè®¾ç½®è®­ç»ƒå‚æ•°çš„ç±»ï¼Œ\n",
    "åŒ…å«äº†è®¸å¤šç”¨äºŽæŽ§åˆ¶è®­ç»ƒè¿‡ç¨‹çš„å‚æ•°ï¼Œä¾‹å¦‚è®­ç»ƒæ—¶çš„å­¦ä¹ çŽ‡ã€batch sizeã€epochæ•°ã€ä¼˜åŒ–å™¨ç±»åž‹ç­‰ç­‰ã€‚è¿™äº›å‚æ•°å¯ä»¥é€šè¿‡å®žä¾‹åŒ–TrainingArgumentsç±»å¹¶ä¼ é€’ç›¸åº”çš„å‚æ•°æ¥è®¾ç½®ã€‚\n",
    "\n",
    "## Traineræ˜¯ä¸€ä¸ªç”¨äºŽè®­ç»ƒæ¨¡åž‹çš„ç±»ï¼Œ\n",
    "å®ƒå¯ä»¥æŽ¥å—ä¸€ä¸ªæ¨¡åž‹å’Œä¸€ä¸ªæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨æŒ‡å®šçš„è®­ç»ƒå‚æ•°è¿›è¡Œè®­ç»ƒã€‚\n",
    "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒTrainerç±»å¯ä»¥è‡ªåŠ¨è¿›è¡Œæ•°æ®åŠ è½½ã€ä¼˜åŒ–å™¨è®¾ç½®ã€æ¨¡åž‹è¯„ä¼°ã€æ—¥å¿—è®°å½•ç­‰æ“ä½œã€‚Trainerç±»è¿˜å¯ä»¥ä½¿ç”¨å¤šä¸ªGPUè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚\n",
    "\n",
    "æ ¸å¿ƒï¼šå¯ä»¥é¿å…æ‰‹åŠ¨ç¼–å†™è®­ç»ƒå¾ªçŽ¯ï¼ˆtraining loopï¼‰çš„ä»£ç ï¼Œä¸éœ€è¦å†å†™def trainå‡½æ•°äº†ã€‚Trainerç±»å·²ç»å®žçŽ°äº†å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€æ¢¯åº¦æ›´æ–°ã€æ¨¡åž‹è¯„ä¼°ç­‰æ­¥éª¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2c59b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "#åˆå§‹åŒ–è®­ç»ƒå‚æ•°\n",
    "args = TrainingArguments(output_dir='./output_dir', # æ¨¡åž‹å‚æ•°ä¿å­˜åœ°å€\n",
    "                         evaluation_strategy='epoch',\n",
    "                         no_cuda=True)\n",
    "# äº›å‚æ•°å¯ä»¥é€šè¿‡å®žä¾‹åŒ–TrainingArgumentsç±»å¹¶ä¼ é€’ç›¸åº”çš„å‚æ•°æ¥è®¾ç½®ã€‚\n",
    "args.num_train_epochs = 1\n",
    "args.learning_rate = 1e-4\n",
    "args.weight_decay = 1e-2\n",
    "args.per_device_eval_batch_size = 32\n",
    "args.per_device_train_batch_size = 16\n",
    "\n",
    "#åˆå§‹åŒ–è®­ç»ƒå™¨ï¼š åœ¨è¿™é‡Œå®šä¹‰\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset_train, # Trainerçš„å¥½å¤„ï¼Œè¿ždatasetéƒ½ä¸ç”¨å®šä¹‰äº†ï¼\n",
    "    eval_dataset=dataset_test, # eval dataä¹Ÿæœ‰å¥½å¤„\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd5b54aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 32\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  1.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4577715992927551,\n",
       " 'eval_accuracy': 0.81,\n",
       " 'eval_runtime': 13.5759,\n",
       " 'eval_samples_per_second': 14.732,\n",
       " 'eval_steps_per_second': 0.516}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ä¸è®­ç»ƒï¼Œç›´æŽ¥æµ‹è¯•åˆå§‹æ¨¡åž‹\n",
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1aedbbd4",
   "metadata": {},
   "source": [
    "å¯ä»¥é¿å…æ‰‹åŠ¨ç¼–å†™è®­ç»ƒå¾ªçŽ¯ï¼ˆtraining loopï¼‰çš„ä»£ç ï¼Œä¸éœ€è¦å†å†™def trainå‡½æ•°äº†ã€‚Trainerç±»å·²ç»å®žçŽ°äº†å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€æ¢¯åº¦æ›´æ–°ã€æ¨¡åž‹è¯„ä¼°ç­‰æ­¥éª¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "104de6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/Users/kennywu/opt/anaconda3/envs/dl/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 63\n",
      "  Number of trainable parameters = 108311810\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [04:41<00:00,  3.88s/it]The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 32\n",
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [04:55<00:00,  3.88s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [04:55<00:00,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4577715992927551, 'eval_accuracy': 0.81, 'eval_runtime': 14.0756, 'eval_samples_per_second': 14.209, 'eval_steps_per_second': 0.497, 'epoch': 1.0}\n",
      "{'train_runtime': 295.1052, 'train_samples_per_second': 3.389, 'train_steps_per_second': 0.213, 'train_loss': 0.629571278889974, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=0.629571278889974, metrics={'train_runtime': 295.1052, 'train_samples_per_second': 3.389, 'train_steps_per_second': 0.213, 'train_loss': 0.629571278889974, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#è®­ç»ƒ 1ä¸ªepoch\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6630698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 32\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  1.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4577715992927551,\n",
       " 'eval_accuracy': 0.81,\n",
       " 'eval_runtime': 13.7887,\n",
       " 'eval_samples_per_second': 14.505,\n",
       " 'eval_steps_per_second': 0.508}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å†æ¬¡è¯„ä»·æ¨¡åž‹\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40bddaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./output_dir\n",
      "Configuration saved in ./output_dir/config.json\n",
      "Model weights saved in ./output_dir/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#ä¿å­˜æ¨¡åž‹çš„ã€å‚æ•°ã€‘ï¼Œä¸æ˜¯æ¨¡åž‹æœ¬èº«\n",
    "trainer.save_model(output_dir='./output_dir')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d123170",
   "metadata": {},
   "source": [
    "# é‡æ–°åŠ åœ¨ä¿å­˜çš„æ¨¡åž‹ï¼Œæ¥é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ed86d9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    label = [i['label'] for i in data]\n",
    "    input_ids = [i['input_ids'] for i in data]\n",
    "    token_type_ids = [i['token_type_ids'] for i in data]\n",
    "    attention_mask = [i['attention_mask'] for i in data]\n",
    "\n",
    "    label = torch.LongTensor(label)\n",
    "    input_ids = torch.LongTensor(input_ids)\n",
    "    token_type_ids = torch.LongTensor(token_type_ids)\n",
    "    attention_mask = torch.LongTensor(attention_mask)\n",
    "\n",
    "    return label, input_ids, token_type_ids, attention_mask\n",
    "\n",
    "\n",
    "#å•ç‹¬ testæ•°æ®åŠ è½½å™¨:  å› ä¸ºä¸æ˜¯trainer ï¼Œæ²¡æœ‰åŠžæ³•ï¼Œåªèƒ½ç”¨torch dataset\n",
    "loader_test = torch.utils.data.DataLoader(dataset=dataset_test, # è¿˜æ˜¯ä¸Šé¢çš„validation\n",
    "                                          batch_size=4,\n",
    "                                          collate_fn=collate_fn,\n",
    "                                        #   shuffle=True,\n",
    "                                            shuffle=False,\n",
    "                                          drop_last=True)\n",
    "\n",
    "for i, (label, input_ids, token_type_ids,\n",
    "        attention_mask) in enumerate(loader_test):\n",
    "    break\n",
    "\n",
    "# label, input_ids, token_type_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19fd71e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# æµ‹è¯•\n",
    "def test():\n",
    "    #åŠ è½½å‚æ•°\n",
    "    model.load_state_dict(torch.load('./output_dir/pytorch_model.bin'))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    #è¿ç®—\n",
    "    out = model(input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask)\n",
    "\n",
    "    #[4, 2] -> [4]\n",
    "    out = out['logits'].argmax(dim=1)\n",
    "\n",
    "    correct = (out == label).sum().item()\n",
    "\n",
    "    return correct / len(label)\n",
    "\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
